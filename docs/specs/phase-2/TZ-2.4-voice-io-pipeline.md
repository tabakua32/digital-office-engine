# TZ-2.4: Voice I/O Pipeline

> **Phase**: 2 â€” Telegram Platform Layer
> **Priority**: P1 (Ğ¿Ğ¾ĞºÑ€Ğ°Ñ‰ĞµĞ½Ğ½Ñ UX, Ğ°Ğ»Ğµ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ğ¸Ğ¹ Ñ€ĞµĞ¶Ğ¸Ğ¼ Ğ¿Ñ€Ğ°Ñ†ÑÑ” Ğ±ĞµĞ· Ğ³Ğ¾Ğ»Ğ¾ÑÑƒ)
> **Sessions**: 1-2
> **Dependencies**: TZ-2.1 (core bot runtime), TZ-2.2 (media sending)
> **Verdict**: COPY 70% | ADAPT 20% | BUILD 10%
> **Architecture ref**: `docs/architecture/phase-2-telegram.md` Â§2.4-D

---

## 1. ĞœĞµÑ‚Ğ°

Ğ”Ğ¾Ğ´Ğ°Ñ‚Ğ¸ Ğ´Ğ²Ğ¾Ğ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğ¹ Ğ³Ğ¾Ğ»Ğ¾ÑĞ¾Ğ²Ğ¸Ğ¹ Ñ–Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹Ñ Ğ´Ğ»Ñ NanoClaw Ñ‡ĞµÑ€ĞµĞ· Telegram:
- **Voice â†’ Text (STT)**: Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ¿Ñ†Ñ–Ñ Ğ³Ğ¾Ğ»Ğ¾ÑĞ¾Ğ²Ğ¸Ñ… Ğ¿Ğ¾Ğ²Ñ–Ğ´Ğ¾Ğ¼Ğ»ĞµĞ½ÑŒ Whisper API
- **Text â†’ Voice (TTS)**: Ğ¾Ğ·Ğ²ÑƒÑ‡ĞµĞ½Ğ½Ñ Ğ²Ñ–Ğ´Ğ¿Ğ¾Ğ²Ñ–Ğ´ĞµĞ¹ Ğ°Ğ³ĞµĞ½Ñ‚Ğ° Ñ‡ĞµÑ€ĞµĞ· Piper/ElevenLabs
- **Hybrid Mode**: Ñ‚ĞµĞºÑÑ‚ + Ğ°ÑƒĞ´Ñ–Ğ¾ Ğ¾Ğ´Ğ½Ğ¾Ñ‡Ğ°ÑĞ½Ğ¾ (accessibility)

**Ğ‘ĞµĞ· Ñ†ÑŒĞ¾Ğ³Ğ¾ Ğ¢Ğ—**: Ğ³Ğ¾Ğ»Ğ¾ÑĞ¾Ğ²Ñ– Ğ¿Ğ¾Ğ²Ñ–Ğ´Ğ¾Ğ¼Ğ»ĞµĞ½Ğ½Ñ Ğ¿Ğ¾ĞºĞ°Ğ·ÑƒÑÑ‚ÑŒÑÑ ÑĞº `[Voice message]` placeholder,
Ğ°Ğ³ĞµĞ½Ñ‚ Ğ½Ğµ Ğ¼Ğ¾Ğ¶Ğµ Ğ¾Ğ±Ñ€Ğ¾Ğ±Ğ¸Ñ‚Ğ¸ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚. Ğ®Ğ·ĞµÑ€Ğ¸ ÑĞºÑ– Ğ´Ğ¸ĞºÑ‚ÑƒÑÑ‚ÑŒ (Ğ¼Ğ¾Ğ±Ñ–Ğ»ÑŒĞ½Ğ¸Ğ¹) â€” Ğ²Ñ–Ğ´ÑÑ–Ñ‡ĞµĞ½Ñ–.

---

## 2. Scope

### 2.1 Included (MVP)

#### A. Voice Input â€” Speech-to-Text

```
User sends voice message (OGG/OPUS, up to 60s)
â”‚
â”œâ”€â”€ telegram.ts (existing message:voice handler):
â”‚   â”œâ”€â”€ getFile(file_id) â†’ file_path on Telegram servers
â”‚   â”œâ”€â”€ Download to temp: /tmp/voice/{message_id}.ogg
â”‚   â””â”€â”€ Pass to VoiceTranscriber
â”‚
â”œâ”€â”€ VoiceTranscriber (STT provider selection):
â”‚   â”œâ”€â”€ PRIMARY: Groq Whisper API (fastest, free tier)
â”‚   â”‚   POST https://api.groq.com/openai/v1/audio/transcriptions
â”‚   â”‚   model: "whisper-large-v3"
â”‚   â”‚   file: voice.ogg
â”‚   â”‚   language: "uk"  (or auto-detect)
â”‚   â”‚
â”‚   â”œâ”€â”€ FALLBACK 1: OpenAI Whisper API
â”‚   â”‚   POST https://api.openai.com/v1/audio/transcriptions
â”‚   â”‚   model: "whisper-1"
â”‚   â”‚
â”‚   â””â”€â”€ FALLBACK 2: Local whisper.cpp (privacy, no API)
â”‚       whisper.cpp -m ggml-large-v3.bin -f voice.ogg -l uk
â”‚
â”œâ”€â”€ Result: { text: "ĞĞ°Ğ¿Ğ¸ÑˆĞ¸ Ğ¼ĞµĞ½Ñ– ÑÑ‚Ğ°Ñ‚Ñ‚Ñ Ğ¿Ñ€Ğ¾ AI Ğ¼Ğ°Ñ€ĞºĞµÑ‚Ğ¸Ğ½Ğ³", language: "uk", duration_s: 5.2 }
â”‚
â”œâ”€â”€ Store in SQLite (messages table):
â”‚   content = "[ğŸ™ Voice] ĞĞ°Ğ¿Ğ¸ÑˆĞ¸ Ğ¼ĞµĞ½Ñ– ÑÑ‚Ğ°Ñ‚Ñ‚Ñ Ğ¿Ñ€Ğ¾ AI Ğ¼Ğ°Ñ€ĞºĞµÑ‚Ğ¸Ğ½Ğ³"
â”‚   (original voice file_id retained for replay)
â”‚
â””â”€â”€ Continue as regular text message in pipeline
```

```typescript
interface VoiceTranscriptionConfig {
  provider: 'groq' | 'openai' | 'local';
  api_key?: string;                     // for Groq/OpenAI
  model: string;                        // whisper-large-v3 / whisper-1
  language?: string;                    // ISO 639-1, null = auto-detect
  local_model_path?: string;            // for whisper.cpp
  max_duration_seconds: number;         // default: 300 (5 min)
  fallback_chain: ('groq' | 'openai' | 'local')[];
}

interface TranscriptionResult {
  text: string;
  language: string;
  duration_seconds: number;
  confidence?: number;
  provider_used: string;
}

class VoiceTranscriber {
  constructor(config: VoiceTranscriptionConfig);

  async transcribe(filePath: string): Promise<TranscriptionResult>;

  // Try providers in order until one succeeds
  private async tryProvider(provider: string, filePath: string): Promise<TranscriptionResult>;
}
```

#### B. Voice Output â€” Text-to-Speech

```
Agent generates text response
â”‚
â”œâ”€â”€ Router checks voice preference:
â”‚   registered_groups.voice_response = 'always' | 'on_request' | 'never'
â”‚   OR: user sent voice message â†’ reply with voice
â”‚
â”œâ”€â”€ TextToSpeechEngine (TTS provider selection):
â”‚   â”œâ”€â”€ PRIMARY: Piper TTS (self-hosted, free, fast)
â”‚   â”‚   Local binary: piper --model uk_UA-lada-medium
â”‚   â”‚   Input: text â†’ Output: .wav â†’ convert to .ogg
â”‚   â”‚
â”‚   â”œâ”€â”€ OPTION: ElevenLabs (high quality, paid)
â”‚   â”‚   POST https://api.elevenlabs.io/v1/text-to-speech/{voice_id}
â”‚   â”‚   model_id: "eleven_multilingual_v2"
â”‚   â”‚
â”‚   â””â”€â”€ OPTION: Google Cloud TTS (reliable, paid)
â”‚       POST https://texttospeech.googleapis.com/v1/text:synthesize
â”‚
â”œâ”€â”€ Convert to OGG/OPUS (Telegram voice format):
â”‚   ffmpeg -i output.wav -c:a libopus output.ogg
â”‚
â””â”€â”€ Send via Telegram:
    sendVoice(chatJid, ogg_buffer, { caption, message_thread_id })
```

```typescript
interface TtsConfig {
  provider: 'piper' | 'elevenlabs' | 'google';
  voice_id?: string;                   // provider-specific voice
  language: string;                    // default: 'uk'
  api_key?: string;                    // for paid providers
  piper_model_path?: string;           // for local Piper
  speed: number;                       // 0.5 - 2.0, default: 1.0
  max_text_length: number;             // default: 4096 chars
}

interface TtsResult {
  audio_buffer: Buffer;                // OGG/OPUS format
  duration_seconds: number;
  provider_used: string;
}

class TextToSpeechEngine {
  constructor(config: TtsConfig);

  async synthesize(text: string): Promise<TtsResult>;

  // Chunking for long text (>max_text_length â†’ multiple audio files)
  async synthesizeLong(text: string): Promise<TtsResult[]>;
}
```

#### C. Hybrid Mode

```typescript
// Hybrid = send both voice + text simultaneously
// Use case: accessibility, user preference, long responses

enum VoiceResponseMode {
  NEVER = 'never',           // text only
  ON_REQUEST = 'on_request', // reply with voice if user sent voice
  ALWAYS = 'always',         // every response has voice
  HYBRID = 'hybrid',         // voice + text together
}

async function sendWithVoice(
  chatJid: string,
  text: string,
  mode: VoiceResponseMode,
  opts?: { message_thread_id?: number; userSentVoice?: boolean }
): Promise<void> {
  const shouldVoice =
    mode === 'always' ||
    mode === 'hybrid' ||
    (mode === 'on_request' && opts?.userSentVoice);

  if (shouldVoice) {
    const tts = await ttsEngine.synthesize(text);
    // Voice with caption (first 1024 chars)
    await telegramChannel.sendVoice(chatJid, tts.audio_buffer, {
      caption: text.slice(0, 200) + (text.length > 200 ? '...' : ''),
      message_thread_id: opts?.message_thread_id,
    });

    if (mode === 'hybrid' && text.length > 200) {
      // Also send full text
      await telegramChannel.sendMessage(chatJid, text, {
        message_thread_id: opts?.message_thread_id,
      });
    }
  } else {
    await telegramChannel.sendMessage(chatJid, text, {
      message_thread_id: opts?.message_thread_id,
    });
  }
}
```

#### D. Voice Settings per Group

```sql
-- Extend registered_groups table
ALTER TABLE registered_groups ADD COLUMN voice_stt_enabled INTEGER DEFAULT 1;
ALTER TABLE registered_groups ADD COLUMN voice_tts_mode TEXT DEFAULT 'on_request';
-- 'never' | 'on_request' | 'always' | 'hybrid'
ALTER TABLE registered_groups ADD COLUMN voice_language TEXT DEFAULT 'uk';
```

### 2.2 Excluded (DEFER)

- **Real-time voice streaming** (live transcription while speaking) â€” future
- **Voice cloning** (custom voice for agent) â€” ElevenLabs feature, Phase 4
- **Multi-language auto-detect** (detect language per message) â€” P2
- **Video message transcription** (video_note circles) â€” P2
- **Music/audio file transcription** â€” not in scope
- **Piper model training** (custom Ukrainian voice) â€” Phase 5

---

## 3. Acceptance Criteria

### P0 â€” Critical Path

- [ ] Voice message â†’ transcription â†’ text stored in SQLite
- [ ] Transcription shown as `[ğŸ™ Voice] <text>` in agent context
- [ ] Agent processes transcribed text as regular message
- [ ] At least one STT provider works (Groq Whisper recommended)
- [ ] Fallback: if STT fails â†’ `[Voice message: transcription failed]`
- [ ] voice_stt_enabled per-group toggle

### P1 â€” Full MVP

- [ ] TTS: agent response â†’ voice message via sendVoice
- [ ] Voice response mode configurable per group (never/on_request/always/hybrid)
- [ ] Hybrid mode: voice + text sent together
- [ ] TTS provider: at least Piper (free) or ElevenLabs (paid)
- [ ] OGG/OPUS output format (native Telegram voice)
- [ ] Long text chunked for TTS (>4096 chars â†’ multiple voice messages)

### P2 â€” Extended

- [ ] Multi-language STT (auto-detect language)
- [ ] Voice message duration tracked in analytics
- [ ] Video note (circle) transcription
- [ ] STT cost tracking (API calls per month)

---

## 4. Implementation Notes

### Key Files to Create/Modify

| File | Action | Description |
|------|--------|-------------|
| `src/voice/transcriber.ts` | CREATE | VoiceTranscriber class with provider chain |
| `src/voice/tts-engine.ts` | CREATE | TextToSpeechEngine class |
| `src/voice/providers/groq.ts` | CREATE | Groq Whisper STT provider |
| `src/voice/providers/openai.ts` | CREATE | OpenAI Whisper STT provider |
| `src/voice/providers/piper.ts` | CREATE | Piper TTS local provider |
| `src/voice/providers/elevenlabs.ts` | CREATE | ElevenLabs TTS provider |
| `src/channels/telegram.ts` | MODIFY | Voice download + sendVoice |
| `src/router.ts` | MODIFY | Voice response mode routing |
| `src/db.ts` | MODIFY | voice columns on registered_groups |

### Key References to Read

| File | Lines | What |
|------|-------|------|
| `docs/architecture/phase-2-telegram.md` | 459-498 | Voice I/O Pipeline spec |
| `src/channels/telegram.ts` | 150-153 | Existing voice handler (placeholder) |
| `src/index.ts` | runAgent() | Output callback for TTS integration |

### Patterns from Reference Repos

| Pattern | Source | Verdict | Usage |
|---------|--------|---------|-------|
| Groq Whisper STT | claudegram (voice integration) | COPY | API client, OGG handling |
| Local whisper.cpp | kai/piper_tts.py + local whisper | ADAPT | Local STT fallback |
| Piper TTS | kai/piper_tts.py | COPY | Self-hosted TTS |
| ElevenLabs TTS | claudegram (ElevenLabs option) | COPY | Paid TTS integration |
| Voice message download | grammY getFile() | COPY | Telegram file download |

### Risks

1. **STT latency** â€” Groq Whisper ~1-3s, acceptable. Local whisper.cpp 5-15s on CPU. Solution: prefer API, local as fallback only.
2. **TTS quality in Ukrainian** â€” Piper Ukrainian voices limited. Solution: ElevenLabs multilingual as option, Piper for free tier.
3. **File size limits** â€” Telegram voice: max 50MB. Solution: chunk long TTS, max 5 min per voice message.
4. **API costs** â€” Groq free tier (limited), OpenAI ~$0.006/min. Solution: per-group enable/disable, usage tracking.
5. **ffmpeg dependency** â€” Required for audio conversion. Solution: Docker image includes ffmpeg, validate on startup.

---

## 5. Testing

### Unit Tests

```typescript
describe('Voice Transcriber', () => {
  test('OGG file transcribed via Groq');
  test('fallback to OpenAI if Groq fails');
  test('fallback to local whisper if APIs fail');
  test('language auto-detect works');
  test('max duration check (reject > 5min)');
  test('result stored as [ğŸ™ Voice] prefix in messages');
});

describe('Text-to-Speech', () => {
  test('short text synthesized to OGG');
  test('long text chunked into multiple audio files');
  test('Piper local provider works');
  test('ElevenLabs API provider works');
  test('output format is OGG/OPUS');
});

describe('Hybrid Mode', () => {
  test('mode=never â†’ text only');
  test('mode=on_request + voice input â†’ voice reply');
  test('mode=on_request + text input â†’ text reply');
  test('mode=always â†’ voice for every response');
  test('mode=hybrid â†’ voice + text together');
});
```

### Integration Tests

```typescript
describe('Voice pipeline E2E', () => {
  test('user sends voice â†’ transcribe â†’ agent processes â†’ text reply');
  test('user sends voice â†’ transcribe â†’ agent processes â†’ voice reply');
  test('voice message with caption â†’ caption appended to transcription');
  test('voice disabled per group â†’ placeholder only');
});
```

---

## 6. Definition of Done

- [ ] Ğ’ÑÑ– P0 acceptance criteria Ğ¿Ñ€Ğ¾Ğ¹Ğ´ĞµĞ½Ñ–
- [ ] Voice message â†’ text transcription works (at least 1 provider)
- [ ] Transcription stored in SQLite, visible in agent context
- [ ] voice_stt_enabled toggle works per group
- [ ] TTS generates valid OGG/OPUS files
- [ ] No regression in existing tests
- [ ] TypeScript compiles without errors

---

_Cross-references: TZ-2.1 (core bot), TZ-2.2 (media sending), TZ-2.3 (streaming for voice responses)_
